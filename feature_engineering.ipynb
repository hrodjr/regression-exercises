{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c9687c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61033a4f",
   "metadata": {},
   "source": [
    "1. Load the tips dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "237fea31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydataset import data\n",
    "tips = data('tips')\n",
    "tips.head()\n",
    "tips['smoker'] = (tips.smoker == 'Yes').astype(int)\n",
    "tips['dinner'] = (tips.time == 'Dinner').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88d0e301",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a. Create a column named tip_percentage. This should be the tip amount divided by the total bill.\n",
    "tips['tip_percentage'] = tips['tip'] / tips['total_bill']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b0a5e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#b. Create a column named price_per_person. This should be the total bill divided by the party size.\n",
    "tips['price_per_person'] = tips['total_bill'] / tips['size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56024447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 244 entries, 1 to 244\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   total_bill        244 non-null    float64\n",
      " 1   tip               244 non-null    float64\n",
      " 2   sex               244 non-null    object \n",
      " 3   smoker            244 non-null    int64  \n",
      " 4   day               244 non-null    object \n",
      " 5   time              244 non-null    object \n",
      " 6   size              244 non-null    int64  \n",
      " 7   dinner            244 non-null    int64  \n",
      " 8   tip_percentage    244 non-null    float64\n",
      " 9   price_per_person  244 non-null    float64\n",
      "dtypes: float64(4), int64(3), object(3)\n",
      "memory usage: 21.0+ KB\n"
     ]
    }
   ],
   "source": [
    "tips.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3df0790a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#c. Before using any of the methods discussed in the lesson...\n",
    "#which features do you think would be most important for predicting the tip amount?\n",
    "#kbest\n",
    "#The tip percentage?\n",
    "#kbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d0c10b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#d. Use select k best and recursive feature elimination to select the top 2 features for predicting tip amount. What are they?\n",
    "X = tips[['total_bill', 'size', 'smoker', 'dinner', 'tip_percentage', 'price_per_person']]\n",
    "y = tips.tip\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=123)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77eda4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['total_bill', 'size'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#kbest\n",
    "\n",
    "kbest = SelectKBest(f_regression, k=2)\n",
    "kbest.fit(X_train_scaled, y_train)\n",
    "kbest.pvalues_\n",
    "kbest.get_support()\n",
    "X_train.columns[kbest.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33dff94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['total_bill', 'tip_percentage'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rfe\n",
    "\n",
    "rfe = RFE(estimator=LinearRegression(), n_features_to_select=2)\n",
    "rfe.fit(X_train_scaled, y_train)\n",
    "rfe.get_support()\n",
    "X_train.columns[rfe.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef34451e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#e. Use select k best and recursive feature elimination to select the top 2 features for predicting tip percentage. What are they?\n",
    "X = tips[['total_bill', 'size', 'smoker', 'dinner', 'tip_percentage', 'price_per_person']]\n",
    "y = tips.tip_percentage\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=123)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cf22908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tip_percentage', 'price_per_person'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#kbest\n",
    "\n",
    "kbest = SelectKBest(f_regression, k=2)\n",
    "kbest.fit(X_train_scaled, y_train)\n",
    "kbest.pvalues_\n",
    "kbest.get_support()\n",
    "X_train.columns[kbest.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16165721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['dinner', 'tip_percentage'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rfe\n",
    "\n",
    "rfe = RFE(estimator=LinearRegression(), n_features_to_select=2)\n",
    "rfe.fit(X_train_scaled, y_train)\n",
    "rfe.get_support()\n",
    "X_train.columns[rfe.get_support()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d9b993",
   "metadata": {},
   "source": [
    " - f. Why do you think select k best and recursive feature elimination might give different answers for the top features? Does this change as you change the number of features your are selecting?\n",
    "    - The features may not be independent of each other, so as the target changes, the top two features may change. As you add more features, the interaction between added features and previous features may cause different predictors of the target."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cc1a0b",
   "metadata": {},
   "source": [
    "2. Write a function named select_kbest that takes in the predictors (X), the target (y), and the number of features to select (k) and returns the names of the top k selected features based on the SelectKBest class. Test your function with the tips dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1891debe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tips[['total_bill', 'size', 'smoker', 'dinner', 'tip_percentage', 'price_per_person']]\n",
    "y = tips.tip\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=123)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54b1d9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X_train\n",
    "y = y_train\n",
    "k = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c36b3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_kbest(x,y,k):\n",
    "    kbest = SelectKBest(f_regression, k=k)\n",
    "    kbest.fit(X_train_scaled, y)\n",
    "    features = kbest.get_support()\n",
    "    return x.columns[kbest.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd5e2932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['total_bill', 'size'], dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_kbest(x,y,k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b93517",
   "metadata": {},
   "source": [
    "3. Write a function named rfe that takes in the predictors, the target, and the number of features to select. It should return the top k features based on the RFE class. Test your function with the tips dataset. You should see the same results as when you did the process manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07b78dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfe(x,y,k):\n",
    "    rfe = RFE(estimator=LinearRegression(), n_features_to_select=k)\n",
    "    rfe.fit(X_train_scaled, y)\n",
    "    return x.columns[rfe.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c6242ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['total_bill', 'tip_percentage'], dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe(x,y,k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5509ee3a",
   "metadata": {},
   "source": [
    "4. Load the swiss dataset and use all the other features to predict Fertility. Find the top 3 features using both select k best and recursive feature elimination (use the functions you just built to help you out)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb401364",
   "metadata": {},
   "outputs": [],
   "source": [
    "swiss = data('swiss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43d4d953",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = swiss[['Agriculture', 'Examination', 'Education', 'Catholic', 'Infant.Mortality']]\n",
    "y = swiss.Fertility\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=123)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "286b8178",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X_train\n",
    "y = y_train\n",
    "k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3579608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Examination', 'Education', 'Catholic'], dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_kbest(x,y,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7415717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Agriculture', 'Education', 'Catholic'], dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe(x,y,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceda9357",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
